<!DOCTYPE html>
<html lang="en-US">

<head>
<meta charset="utf-8" />
<meta name="author" content="Levi John Wolf" />
<meta name="description" content="just a geograblog" />
<meta name="keywords" content="" />
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<meta name="generator" content="Hugo 0.36" />

<link rel="canonical" href="/how-one-weird-trick-helps-you-evaluate-correlated/">
<base href="/" />
<meta property="og:title" content="How one weird trick helps you evaluate correlated Normal distributions quickly" />
<meta property="og:description" content="Sorry, couldn’t resist the opportunity to buzzfeed this research blog :)
I’ve been trying to get really efficient at writing samplers for various Bayesian spatial models. And, typically, this involves clever numerical tricks, trying to avoid computing either log determinants or matrix inverses by keeping around matrix factorizations or finding derived products that you can persist between iterations. Some of this has come to fruition in my sparse log determinant work, but I’m always looking for computation speed gains, especially as some of the targets I&rsquo;ve optimized are drying up." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/how-one-weird-trick-helps-you-evaluate-correlated/" />



<meta property="article:published_time" content="2016-10-07T20:09:36&#43;00:00"/>

<meta property="article:modified_time" content="2016-10-07T20:09:36&#43;00:00"/>











<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="How one weird trick helps you evaluate correlated Normal distributions quickly"/>
<meta name="twitter:description" content="Sorry, couldn’t resist the opportunity to buzzfeed this research blog :)
I’ve been trying to get really efficient at writing samplers for various Bayesian spatial models. And, typically, this involves clever numerical tricks, trying to avoid computing either log determinants or matrix inverses by keeping around matrix factorizations or finding derived products that you can persist between iterations. Some of this has come to fruition in my sparse log determinant work, but I’m always looking for computation speed gains, especially as some of the targets I&rsquo;ve optimized are drying up."/>



<meta itemprop="name" content="How one weird trick helps you evaluate correlated Normal distributions quickly">
<meta itemprop="description" content="Sorry, couldn’t resist the opportunity to buzzfeed this research blog :)
I’ve been trying to get really efficient at writing samplers for various Bayesian spatial models. And, typically, this involves clever numerical tricks, trying to avoid computing either log determinants or matrix inverses by keeping around matrix factorizations or finding derived products that you can persist between iterations. Some of this has come to fruition in my sparse log determinant work, but I’m always looking for computation speed gains, especially as some of the targets I&rsquo;ve optimized are drying up.">


<meta itemprop="datePublished" content="2016-10-07T20:09:36&#43;00:00" />
<meta itemprop="dateModified" content="2016-10-07T20:09:36&#43;00:00" />
<meta itemprop="wordCount" content="259">



<meta itemprop="keywords" content="python, statistics, computation,imported," />


<link rel="stylesheet" href="css/layout.css" />
<style type="text/css">
body {
  background-color: #f5f5f5;
  color: #444444;
}

a { color: #444444; }

pre {
  background: ;
  border: 1px solid #444444;
  border-radius: 5px;
}

code {
  background: ;
}

blockquote {
  background: ;
  border-left: 3px solid #444444;
}

table {
  margin: 1em auto;
  border-collapse: collapse;
}

table, th, td {
  border: 1px solid #444444;
}

th {
  background: #444444;
  color: #f5f5f5;
}

.siteTitle a { color: #e84848; }

.post .content h1{ color: #e84848; }
.post .content h2{ color: #e84848; }
.post .content h3{ color: #e84848; }
.post .content h4{ color: #e84848; }
.post .content h5{ color: #e84848; }
.post .content h6{ color: #e84848; }
.post .content a:hover { color: #e84848; }
.social-link:hover { color: #e84848; }
.nav-item-title:hover { color: #e84848; }
.tag a:hover { color: #e84848; }
.copyright { color: #404040 }
.poweredby { color: #404040 }
.poweredby a { color: #404040; }
.post-preview .title a{ color: #e84848; }
.content-item a:hover{
  text-decoration: underline;
  color: #e84848;
}
.post-list .title { color: #e84848; }
.rmore { color: #e84848; }
.terms .term a:hover {
  text-decoration: underline;
  color: #e84848;
}

</style>



<title>


     How one weird trick helps you evaluate correlated Normal distributions quickly 

</title>

</head>


<body>
<div class="main">
<header>

<div class="header-bar">

  <nav>
    <div class="siteTitle">
      <a href="/">Yet Another Geographer</a>
    </div> 

    
    
    <a class="nav-item" href="/about/"><div class="nav-item-title">About | </div></a>
    
    <a class="nav-item" href="https://www.dropbox.com/s/y5mjkduq7bopzex/currvita.pdf?dl=0"><div class="nav-item-title"> CV |  </div></a>
    
    <a class="nav-item" href="http://www.bristol.ac.uk/geography/people/levi-j-wolf/overview.html"><div class="nav-item-title"> Bristol |  </div></a>
    
    <a class="nav-item" href="https://spatial.uchicago.edu"><div class="nav-item-title"> Chicago |  </div></a>
    
    <a class="nav-item" href="https://spatial.uchicago.edu"><div class="nav-item-title"> UCR |  </div></a>
    
    <a class="nav-item" href="/talks/"><div class="nav-item-title"> Talks | </div></a>
    
    <a class="nav-item active" href="/post/"><div class="nav-item-title">Posts</div></a>
    

  </nav>
</div>



</header>


<article class="post">
    <h1 class="title"> How one weird trick helps you evaluate correlated Normal distributions quickly </h1>
    <div class="content"> <p><figure data-orig-width="679" data-orig-height="420" class="tmblr-full"><img src="http://78.media.tumblr.com/64a57a8fc5e43b8521e35d7b35c951f2/tumblr_inline_oepcbsZ5u91qeher0_540.png" alt="image" data-orig-width="679" data-orig-height="420"/></figure><p>Sorry, couldn’t resist the opportunity to <a href="https://en.wikipedia.org/wiki/One_weird_trick_advertisements" target="_blank">buzzfeed this research blog :)</a></p><p>I’ve been trying to get really efficient at writing samplers for various Bayesian spatial models. And, typically, this involves clever numerical tricks, trying to avoid computing either log determinants or matrix inverses by keeping around matrix factorizations or finding derived products that you can persist between iterations. Some of this has come to fruition in my sparse log determinant work, but I’m always looking for computation speed gains, especially as some of the targets I&rsquo;ve optimized are drying up.<br/></p><p>One I’ve just identified might be in sampling kernels that look like multivariate normal kernels. Naively, when you write the logp of a normal distribution, you’d expect to do the following kinds of computations. For respone <code>Y</code>, linear predictor <code>XBeta</code>, and a dense correlated covariance matrix <code>Sigma</code>, I&rsquo;d naively compute a normal kernel using the following code:</p><pre><code>e = Y - XBeta
Sigma_i = np.linalg.inv(Sigma)
kernel = -.5*np.linalg.multi_dot(e.T, Sigma_i, e.T)
</code></pre><p>But, there&rsquo;s actually a siginficant gain if you use the solve method instead of inverting <code>Sigma</code> by itself.</p><pre><code>e = Y - XBeta
kernel = np.linalg.solve(Sigma, e).T.dot(e)
</code></pre><p>Who knew?
How much faster? Timings are attached for covariance matrices from 5^2 to 20^2 in dimension. Left is the solve method, right is the inverse method. While I’m scaling these up for much larger spatially-correlated error models as I write, it looks to me like a promising speed gain!</p><p><i>edit: scaling quite nicely up to 50^2. I’ll have to see where the sparse math goes with this trick. </i></p></p>

<p><small><i> imported from:</i> <a href='https://yetanothergeographer.tumblr.com/151491815214/how-one-weird-trick-helps-you-evaluate-correlated'<tt>yetanothergeographer</tt></a></small></p>
 </div>
    <footer class="post-footer">

  <div class="post-footer-data">
    
<div class="tags">
    
      <div class="tag">
        <a href="/tags/python">#python</a>
      </div>
    
      <div class="tag">
        <a href="/tags/statistics"># statistics</a>
      </div>
    
      <div class="tag">
        <a href="/tags/computation"># computation</a>
      </div>
    
      <div class="tag">
        <a href="/tags/imported">#imported</a>
      </div>
    
</div>

    <div class="date"> Oct 7, 2016 </div>
  </div>

</footer>


  


</article>

  <footer>

  <div class="social-links-footer">

  
  <a href="mailto:levi.john.wolf@gmail.com"><div class="social-link">Email</div></a>
  

  
  <a href="https://github.com/ljwolf" target="_blank"><div class="social-link">GitHub</div></a>
  

  

  
  <a href="https://twitter.com/levijohnwolf" target="_blank"><div class="social-link">Twitter</div></a>
  

  

  <div class="social-link">
  <a href="/index.xml" target="_blank">RSS</a>
  </div>

</div>


  <div class="copyright">  </div>

  <div class="poweredby">
      thanks, <a href="https://gohugo.io/">Hugo</a>.
  </div>

  </footer>

</div> 

</body>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

</html>

