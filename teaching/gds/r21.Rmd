---
title: "Validating models"
output:
  tufte::tufte_html: default
  tufte::tufte_handout: default---
---

# Training (and assessing) models in DS

Today, we'll cover a little bit of using the `caret` package for model training. 

```{r}
library(caret)
library(sf)
library(tidyverse)
```

```{r}
spotify <- read_csv('../data/midterm-songs.csv')
```

```{r}
ggplot(spotify, aes(x=tempo, y=danceability)) + 
  geom_point(alpha=.1) + 
  geom_smooth(se=F, method='lm', color='red') + 
  geom_smooth(se=F)
```
First, note that the linear model really does not work here... it totally misses the fact that danceability gets *better* with some rises in tempo, then decreases after the most danceable tempos of around 100 beats per minute. Second, note that the warning for the second smoother says that the "method = gam", with "formula = s(x, bs='cs')". This means that the model used is a [*generalized additive model*](https://noamross.github.io/gams-in-r-course/chapter1) (from the `mcgv` package), with a formula `y ~ s(x, bs='cs')`, which means:

- `y`, our outcome, 
- is modeled as a *smooth* `s()` function of `x`, 
- where the "basis function" `bs` of the smooth (that is, the function used for each of the x ranges) 
- is a cubic shrinkage spline `cs`.
  
You could fit this model directly, too! 
```{r}
library(mgcv)

m1 = gam(danceability ~ s(tempo, bs='cs'), data=spotify)
```
This is your first Generalized Additive Model, a spline model!

Let's compare this to a standard linear model:
```{r}
m0 = lm(danceability ~ tempo, data=spotify)
```

We can see the predictions from the two easily. Let's first build a "fake " dataframe that has some info we want to predict: tempos evenly spaced from zero to 200: 
```{r}
scenario = data.frame(tempo = seq(0,200, 1))
scenario
```
Then, we can use the `predict()` function to get each of the models' predictions:
```{r}
p0 = predict(m0, scenario)
p1 = predict(m1, scenario)
scenario <- scenario %>% mutate(p0 = p0, p1 = p1)
```


Plotting these ourselves:^[Remember, when I use the full stop (`.`) in `data=.`, I'm saying "stick the output of the pipe right at the stop!"]
```{r}
spotify %>%
  ggplot(data=., aes(x=tempo, y=danceability)) + 
    geom_point(alpha=.1) + 
    geom_line(data = scenario, 
              aes(y=p0), color='red', lwd=1) + 
    geom_line(data = scenario, 
              aes(y=p1), color='blue', lwd=1)
```
When it comes to choosing between the two models, we can use the *mean squared error*, which is the average squared error of the two models. First, thinking about the standard linear model:

```{r}
mean(residuals(m0)^2)

```
And second, about our smooth model:
```{r}
mean(residuals(m1)^2)
```
The GAM has a lower squared error. And, we can see that the bias in predictions, too; the Linear model really under-predicts danceablity for slow songs, while the generalized additive model 

```{r}
g1 = spotify %>% mutate(r0 = residuals(m0), 
                   r1 = residuals(m1)) %>%
  ggplot(., aes(x=tempo, y=r1)) + 
  geom_point(aes(y=r1), color='darkred', alpha=.1) + 
  ggtitle('Generalized Additive Model') + 
  ylim(-.8, .4)

g2 = spotify %>% mutate(r0 = residuals(m0), 
                   r1 = residuals(m1)) %>%
  ggplot(., aes(x=tempo, y=r0)) +
  geom_point(aes(y=r0), color='darkblue', alpha=.1) + 
  ggtitle("Linear Model")+ 
  ylim(-.8, .4)

ggarrange(g1, g2)
```

# A general interface to data science models

Now, you could learn all the different packages to fit models, but they all generally vary in their interfaces, options, and methods to train. So, the `caret` package attempts to make things easy, providing a standard interface for model fitting and comparison. For the same example we did above:

```{r}
library(caret)
cm0 <- train(danceability ~ tempo, data=spotify, method='lm')
```
And, although the package does not support more complex generalized additive models, it does support very simple ones like the one we used here:

```{r}
cm1 <- train(danceability ~ tempo, data=spotify, method='gam')
```

A full list of models is [mind-bogglingly big](https://topepo.github.io/caret/available-models.html).

# Crossvalidation

The nice thing about using caret is that you get a standardized interface to training models. For example, crossvalidation (for any model type) can be done very easily using the `trainControl` method. For example, to set up cross-validation with 5 folds, repeated 10 times:

```{r}
training_options <- trainControl(method='repeatedcv', 
                                 number=5, # number of "folds"
                                 repeats=10 # how many times to repeat the procedure
                                 )
```

Then, we can do this on a linear model:
```{r}
cm0_cv <- train(danceability ~ tempo, 
                data=spotify, 
                method='lm',
                trControl=training_options)
cm0_cv
```
Which shows the R-squared, the root mean square error, and the mean absolute error (MAE). We can access the fitted model directly:

```{r}
cm0_cv$finalModel
```
or compare two models:
```{r}
cm1_cv <- train(danceability ~ tempo, 
                data=spotify, 
                method='gam', 
                trControl=training_options)
cm1_cv
```