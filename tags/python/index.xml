<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on Yet Another Geographer</title>
    <link>/tags/python/</link>
    <description>Recent content in Python on Yet Another Geographer</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Mon, 12 Mar 2018 23:52:32 +0000</lastBuildDate>
    
	<atom:link href="/tags/python/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Annoscatter</title>
      <link>/post/annoscatter/</link>
      <pubDate>Mon, 12 Mar 2018 23:52:32 +0000</pubDate>
      
      <guid>/post/annoscatter/</guid>
      <description>I found this function super useful in my dissertation and more generally in my work. What it does is take x,y coordinates and a set of strings and annotates a scatterplot using those labels. For example, here&amp;rsquo;s a figure from my dissertation where I use it to annotate a plot of regression leverage by year. I jitter the points a little to provide legibility to the text labels, but basically it&amp;rsquo;s just a call like annoscatter(df.</description>
    </item>
    
    <item>
      <title>Spatial Econometric HMC in Python</title>
      <link>/spatial-econometric-hmc-in-python/</link>
      <pubDate>Fri, 24 Mar 2017 15:52:55 +0000</pubDate>
      
      <guid>/spatial-econometric-hmc-in-python/</guid>
      <description>I almost forgot to mention this here: I’ve put up code on how to use some common spatial econometric models in Stan and PyMC3. For PyMC3, the implementations provide two methods that make the evaluation of thelikelihood very fast when compared to PyMC3′s native logdet function. These two methods are implemented as custom theano ops that are cache some information to improve the speed of the gradient evaluation. One uses sparse LU factorization to provides the log determinant very quickly without precomputation.</description>
    </item>
    
    <item>
      <title>all those p-values will be lost in time</title>
      <link>/all-those-p-values-will-be-lost-in-time-like/</link>
      <pubDate>Wed, 22 Feb 2017 22:09:11 +0000</pubDate>
      
      <guid>/all-those-p-values-will-be-lost-in-time-like/</guid>
      <description>like tears in rain.
 imported from: yetanothergeographer</description>
    </item>
    
    <item>
      <title>A short exploration of the 2016 electoral swing</title>
      <link>/a-short-exploration-of-the-2016-electoral-swing/</link>
      <pubDate>Tue, 29 Nov 2016 00:07:16 +0000</pubDate>
      
      <guid>/a-short-exploration-of-the-2016-electoral-swing/</guid>
      <description>I’m pretty skeptical of the generalized uniform partisan swing assumption in gerrymandering models. Part of this is due to some skepticism about how swing actually occurs in elections generally. If we don’t have an explicit “shock” model for our counterfactuals, they’re probably not going to replicate true experienced electoral swings well. 
I’ve put together a notebook where I go through and explore some modeling of the 2012-2016 electoral swing at the county level.</description>
    </item>
    
    <item>
      <title>Working between python 2 and python 3</title>
      <link>/working-between-python-2-and-python-3/</link>
      <pubDate>Fri, 18 Nov 2016 01:52:16 +0000</pubDate>
      
      <guid>/working-between-python-2-and-python-3/</guid>
      <description>I am so done with programming for python 2.
This is the convergence in a spatial parameter in a spatial model I’m working with. This is a very long run that took a few hours to complete. Tests of this on my (python 3) compute server went fine, tuned correctly, but didn’t have this dramatic convergence.
Once the sampling finished, I looked at the acceptance rate and, sure enough, the AR on the metropolis step of this Gibbs sampler was like&amp;hellip; .</description>
    </item>
    
    <item>
      <title>Yet another elections simulator</title>
      <link>/yet-another-elections-simulator/</link>
      <pubDate>Tue, 25 Oct 2016 19:53:11 +0000</pubDate>
      
      <guid>/yet-another-elections-simulator/</guid>
      <description>After reading Wasserman’s 2012 blog post about mixture models, I’m glad that I’ve finally figured out &amp;amp; implemented the Gelman-King 1994 electoral model as well. Based on pretty straghtforward regression modeling, the setup trades the representational simplicity of the Linzer GMM model for a much more complex modeling structure, but that I guess provides better guarantees about its own properties. Regardless, it’s a bummer that these guys stuff, theLinzer 2012 paper on simulating seats/votes curves using gaussian mixtures &amp;amp; the JudgeIt stuff for the GK1994 paper was never merged into the political science computational library.</description>
    </item>
    
    <item>
      <title>elections simulators</title>
      <link>/finally-got-this-elections-simulator-working-the/</link>
      <pubDate>Tue, 18 Oct 2016 14:00:17 +0000</pubDate>
      
      <guid>/finally-got-this-elections-simulator-working-the/</guid>
      <description>finally got this elections simulator working, based on Linzer&amp;rsquo;s 2012 paper on gaussian mixture modelling for elections data.
 imported from: yetanothergeographer</description>
    </item>
    
    <item>
      <title>libsixel is real cool</title>
      <link>/every-time-i-use-a-sixel-based-library-it-just/</link>
      <pubDate>Mon, 10 Oct 2016 19:25:04 +0000</pubDate>
      
      <guid>/every-time-i-use-a-sixel-based-library-it-just/</guid>
      <description>images directly in the terminal! no fuss! although you have to use a special terminal emulator&amp;hellip;
 imported from: yetanothergeographer</description>
    </item>
    
    <item>
      <title>metropolis-within-gibbs</title>
      <link>/at-top-a-metropolis-within-gibbs-sampled-sar/</link>
      <pubDate>Sun, 09 Oct 2016 18:53:35 +0000</pubDate>
      
      <guid>/at-top-a-metropolis-within-gibbs-sampled-sar/</guid>
      <description>my spatially-correlated variance components model is finally coming together :)
 imported from: yetanothergeographer</description>
    </item>
    
    <item>
      <title>How one weird trick helps you evaluate correlated Normal distributions quickly</title>
      <link>/how-one-weird-trick-helps-you-evaluate-correlated/</link>
      <pubDate>Fri, 07 Oct 2016 20:09:36 +0000</pubDate>
      
      <guid>/how-one-weird-trick-helps-you-evaluate-correlated/</guid>
      <description>Sorry, couldn’t resist the opportunity to buzzfeed this research blog :)
I’ve been trying to get really efficient at writing samplers for various Bayesian spatial models. And, typically, this involves clever numerical tricks, trying to avoid computing either log determinants or matrix inverses by keeping around matrix factorizations or finding derived products that you can persist between iterations. Some of this has come to fruition in my sparse log determinant work, but I’m always looking for computation speed gains, especially as some of the targets I&amp;rsquo;ve optimized are drying up.</description>
    </item>
    
    <item>
      <title>something&#39;s up with PyMC3&#39;s diagnostics...</title>
      <link>/because-i-actually-post-all-of-my-stuff-to-gists/</link>
      <pubDate>Thu, 29 Sep 2016 00:13:20 +0000</pubDate>
      
      <guid>/because-i-actually-post-all-of-my-stuff-to-gists/</guid>
      <description>above is their geweke statistic versus my version &amp;amp; that found in CODA.
Not sure what&amp;rsquo;s up, but it&amp;rsquo;s not good&amp;hellip;
 imported from: yetanothergeographer</description>
    </item>
    
    <item>
      <title>Formally Winding down GSOC</title>
      <link>/formally-winding-down-gsoc/</link>
      <pubDate>Wed, 17 Aug 2016 14:15:52 +0000</pubDate>
      
      <guid>/formally-winding-down-gsoc/</guid>
      <description>This week, I’ve been really bringing the work on GSOC to a close. Thus, I’ve linked to a notebook where I walk through the various work I’ve done in the project. What a ride.  imported from: yetanothergeographer</description>
    </item>
    
    <item>
      <title>spatially-varying components models are finally coming together</title>
      <link>/as-im-having-to-wind-down-on-summer-of-code-work/</link>
      <pubDate>Sat, 06 Aug 2016 00:09:56 +0000</pubDate>
      
      <guid>/as-im-having-to-wind-down-on-summer-of-code-work/</guid>
      <description>now that the google summer of code has winded down.
 imported from: yetanothergeographer</description>
    </item>
    
    <item>
      <title>A Post-SciPy Chicago Update</title>
      <link>/a-post-scipy-chicago-update/</link>
      <pubDate>Mon, 25 Jul 2016 02:52:31 +0000</pubDate>
      
      <guid>/a-post-scipy-chicago-update/</guid>
      <description>After a bit of a whirlwind, going to SciPy and then relocating to Chicago for a bit, I figure I&amp;rsquo;ve collected enough thoughts to update on my summer of code project, as well as some of the discussion we&amp;rsquo;ve had in the library recently.
I&amp;rsquo;ve actually seen a lot of feedback on quite a bit of my postings since my post on handling burnout as a graduate student. But, I&amp;rsquo;ve been forgetting to tag posts so that they&amp;rsquo;d show up in the GSOC aggregator!</description>
    </item>
    
    <item>
      <title>Using Soft Dependencies Effectively</title>
      <link>/using-soft-dependencies-effectively/</link>
      <pubDate>Tue, 12 Jul 2016 04:39:00 +0000</pubDate>
      
      <guid>/using-soft-dependencies-effectively/</guid>
      <description>I wrote a little guide for my fellow library devs about how to use soft dependencies effectively. This moves in tandem with some work on enabling PySAL to have a consistent user experience while leveraging the newest &amp;amp; best libraries for scientific computation. Since most of the work I’ve been doing involves using soft dependencies with the library, it’s important to get this right. The gist is here.
 imported from: yetanothergeographer</description>
    </item>
    
    <item>
      <title>Partially Applied classes with __new__</title>
      <link>/partially-applied-classes-with-new/</link>
      <pubDate>Thu, 23 Jun 2016 20:59:03 +0000</pubDate>
      
      <guid>/partially-applied-classes-with-new/</guid>
      <description>Python’s got some pretty cool ways to enable unorthodox behavior. For my project, I’ve found myself writing a lot of closures around our existing class init functions, and have decided it might be easier &amp;amp; more consistent to express this as what it really is: partial application. Partial application is pretty simple to enable for python class constructors, since the separate new method allows you to construct closures around initialization routines.</description>
    </item>
    
    <item>
      <title>log deterimnants</title>
      <link>/thisll-be-a-more-lucid-writeup-of-what-i-was/</link>
      <pubDate>Fri, 17 Jun 2016 18:27:53 +0000</pubDate>
      
      <guid>/thisll-be-a-more-lucid-writeup-of-what-i-was/</guid>
      <description>Recently, I’ve been working on getting spatial econometric models implemented using PyMC3. I’ll put pu an example later, but right now I’m primarily concerned with making the example more efficient for slightly larger datasets.
You see, some spatial econometric models require that the log determinant of a very large matrix be computed. Since most of these models are estimated using Maximum Likelihood, this is somewhat painful, but can be minimized by exploiting sparsity in the large matrix.</description>
    </item>
    
    <item>
      <title>but yet so far</title>
      <link>/man-im-so-close-to-a-pretty-massive-speedup-of/</link>
      <pubDate>Fri, 17 Jun 2016 05:02:53 +0000</pubDate>
      
      <guid>/man-im-so-close-to-a-pretty-massive-speedup-of/</guid>
      <description>imported from: yetanothergeographer</description>
    </item>
    
    <item>
      <title>GSOC Call Notes, June 6 2016</title>
      <link>/gsoc-call-notes-june-6-2016/</link>
      <pubDate>Mon, 06 Jun 2016 19:11:28 +0000</pubDate>
      
      <guid>/gsoc-call-notes-june-6-2016/</guid>
      <description>I&amp;rsquo;ve had to take a break from the spatial hierarchical linear modeling kick I&amp;rsquo;ve been on recently to get back to some GSOC work.
Today, I had my weekly call with my mentors.
On today&amp;rsquo;s call, my mentors and I discussed a few things.
Testing &amp;amp; Merging of project code Since many of the improvements I&amp;rsquo;m making to the library are module-by-module, I was advised to submit PRs when a logical unit of contribution is ready to ship.</description>
    </item>
    
    <item>
      <title>The Beginnings of a new API</title>
      <link>/the-beginnings-of-a-new-api/</link>
      <pubDate>Fri, 03 Jun 2016 20:07:42 +0000</pubDate>
      
      <guid>/the-beginnings-of-a-new-api/</guid>
      <description>NOTE: A demo of the relevant code I&amp;rsquo;m referring to for the new labelled array API in pysal.weights in this update is available in this notebook, and the actual code lives in a weights2 module in my gsoc feature branch.
I&amp;rsquo;ve decided to target our weights module to prototype the labelled array interface. In general, we&amp;rsquo;ll need extensions built into at least our exploratory spatial data analysis module, esda, our spatial regression module, spreg, and our spatial dynamics module, spatial_dynamics.</description>
    </item>
    
    <item>
      <title>sampling distributions at each grid site</title>
      <link>/visual-display-of-complex-data-can-be-pretty/</link>
      <pubDate>Fri, 03 Jun 2016 01:40:17 +0000</pubDate>
      
      <guid>/visual-display-of-complex-data-can-be-pretty/</guid>
      <description>This is a visualization of one hierarchical parameter from a a spatially-varying coefficient process model, estimated on a simple 10x10 grid. The model itself is a pretty neat way to specify a spatially-varying process with an efficient formal structure. I won&amp;rsquo;t go into the specification here, but my growing interest in MLM/HLM means I&amp;rsquo;ll probably be posting about SVCP-style models more frequently.
The point of this, though, is that characterizing both the spatial distribution of hierarchical parameter means and the distributions of those parameters for each individual unit is hard.</description>
    </item>
    
    <item>
      <title>Call notes about my Request for Comment</title>
      <link>/call-notes-about-my-request-for-comment/</link>
      <pubDate>Wed, 25 May 2016 04:23:38 +0000</pubDate>
      
      <guid>/call-notes-about-my-request-for-comment/</guid>
      <description>The followng were comments I recieved on my Request for Comment submitted a bit ago.
Questions about Request for Comment: What should I prioritize? NOGR or Labeled Array Interface? Labeled Array. This is critical to get correct, and will make NOGR need and scope clearer. How deep into PySAL should the Labeled Array interface go? Design it like the library were getting built now. Do not fail on import. Instead, use soft dependencies/optional import patterns if necessary, write Python3-only components safely, so that new features can be leveraged.</description>
    </item>
    
    <item>
      <title>GSOC Introduction</title>
      <link>/gsoc-introduction/</link>
      <pubDate>Mon, 23 May 2016 17:20:58 +0000</pubDate>
      
      <guid>/gsoc-introduction/</guid>
      <description>Hey all!
While I may have put the cart before the horse in doing an RFC before an introduction, it’s never too late :)
My name is Levi John Wolf. I am a PhD candidate at Arizona State University. I study spatial statistics, econometrics, &amp;amp; polimetrics, focusing on campaigns, elections, &amp;amp; inequality. I am a Google Summer of Code student for the Python Spatial Analysis Library (PySAL), under the Python Software Foundation (PSF).</description>
    </item>
    
    <item>
      <title>RFC for GSOC Feedback</title>
      <link>/rfc-for-gsoc-feedback/</link>
      <pubDate>Thu, 19 May 2016 19:12:11 +0000</pubDate>
      
      <guid>/rfc-for-gsoc-feedback/</guid>
      <description>Clarifying a Core Data Model for PySAL  Gist here From my perspective, I see my proposal for GSOC as containing two oblique foci. My hope in drafting this notebook for my fellow authors is to make this clear.
I think at this point, many people who use &amp;amp; develop PySAL would like to see better tooling for Pandas$\leftrightarrow$PySAL interaction. This was started by Luc, Dani, &amp;amp; myself in the pysal.</description>
    </item>
    
    <item>
      <title>Puzzles about (mis)Replication</title>
      <link>/puzzles-about-misreplication/</link>
      <pubDate>Wed, 18 May 2016 20:48:03 +0000</pubDate>
      
      <guid>/puzzles-about-misreplication/</guid>
      <description>So, a while back, I was using a new compactness metric to extend some gerrymandering studies. In attempting the replication, I found some minor math errors in the original paper that made it diffcult to get valid values for the statistic.
After trying multiple times to verify whether it was my code or if the published statistic had some typographical error, I went to the original author, shared my concerns, and found that it did.</description>
    </item>
    
    <item>
      <title>Bringing Classifiers Alive in PySAL</title>
      <link>/bringing-classifiers-alive-in-pysal/</link>
      <pubDate>Thu, 24 Mar 2016 22:32:23 +0000</pubDate>
      
      <guid>/bringing-classifiers-alive-in-pysal/</guid>
      <description>I&amp;rsquo;ve talked a lot to fellow developers about making PySAL objects more than containers for the results of a statistical procedure.
One way I think we can do this is to focus on methods like predict, find, update, or reclassify.
So, here, I&amp;rsquo;ll show the way I&amp;rsquo;ve implemented a simple API to update map classifiers by defining their __call__ method.
   In [2]: import pysal as ps</description>
    </item>
    
    <item>
      <title>yep, that&#39;s an image from within the terminal</title>
      <link>/yep-thats-image-view-from-within-a-terminal/</link>
      <pubDate>Wed, 23 Mar 2016 03:41:38 +0000</pubDate>
      
      <guid>/yep-thats-image-view-from-within-a-terminal/</guid>
      <description>thanks, libsixel
 imported from: yetanothergeographer</description>
    </item>
    
    <item>
      <title>Trivial Python Multiprocessing</title>
      <link>/trivial-python-multiprocessing/</link>
      <pubDate>Tue, 16 Feb 2016 21:18:10 +0000</pubDate>
      
      <guid>/trivial-python-multiprocessing/</guid>
      <description>I just wrote up a notebook for a fellow PhD student on how I use python&amp;rsquo;s builtin multiprocessing library to do embarassingly parallel computations much faster. Every time I think about it, I&amp;rsquo;m floored at how simple using the builtin multiprocessing library is for certain operations.
There&amp;rsquo;s a ton of uncertainty out there around the state of parallel computing in Python, and I&amp;rsquo;m not an expert. But, I figure if it&amp;rsquo;s good enough for the unicorn I worked for, it&amp;rsquo;s good enough for a computational social scientist.</description>
    </item>
    
    <item>
      <title>A bite of a “free lunch” optimizing numerical routines in Python</title>
      <link>/a-bite-of-a-free-lunch-optimizing-numerical/</link>
      <pubDate>Tue, 16 Feb 2016 00:09:02 +0000</pubDate>
      
      <guid>/a-bite-of-a-free-lunch-optimizing-numerical/</guid>
      <description>tl;dr: ask yourself these before you deadlift optimize code
I use Python pretty much daily, but I’m definitely not a Python wizard. Now that I’m done with converting the Python Spatial Analytics Library to use Python 3 compatible idioms, I took a break from refactoring more generally.
But, in doing two small tests/stabs at refactoring for speed &amp;amp; memory usage, I’m reminded why optimizing numerical code is so hard. I’ve heard &amp;ldquo;there ain’t no such thing as a free lunch,” so I’m usually wary about getting into performance optimization stuff, but these two recent instances really drive this point home for me again.</description>
    </item>
    
    <item>
      <title>A Tricky Bit Implementing Skyum’s Algorithm</title>
      <link>/a-tricky-bit-implementing-skyums-algorithm/</link>
      <pubDate>Thu, 21 Jan 2016 02:07:35 +0000</pubDate>
      
      <guid>/a-tricky-bit-implementing-skyums-algorithm/</guid>
      <description>My dissertation is on gerrymandering. While I’m very sure it’s not the best way to do it, many people use geometric measures of district shapes as a way to detect gerrymandering. 
One of the oldest and most well-used is the Reock measure, first developed in 1960. It’s a bit tougher than other kinds of gerrymandering measures to construct. For instance, the most popular measure is the Polsby-Popper measure, as used in this Washinton Post piece, is actually identical to a shape measure calle the Isoperimetric Quotient.</description>
    </item>
    
    <item>
      <title>The competence ceiling</title>
      <link>/the-competence-ceiling/</link>
      <pubDate>Wed, 09 Dec 2015 20:45:53 +0000</pubDate>
      
      <guid>/the-competence-ceiling/</guid>
      <description>After programming Haskell, R, or Python for about 6 years now, I feel like I’m sufficiently skilled with Python to make anything that I want to do in python immediate.
I understand its execution model. I feel very confident in my understandings of how python objects work. The fastest/lightest way to get what I want seems like it’s relatively easy to achieve.
In a sense, I feel competent. And that makes me feel a little complacent, and a little stagnant.</description>
    </item>
    
    <item>
      <title>and bears, oh my</title>
      <link>/having-a-last-name-of-wolf-has-never-been-an/</link>
      <pubDate>Fri, 09 Oct 2015 01:21:32 +0000</pubDate>
      
      <guid>/having-a-last-name-of-wolf-has-never-been-an/</guid>
      <description>imported from: yetanothergeographer</description>
    </item>
    
    <item>
      <title>Some realizations on FOSS-Governance</title>
      <link>/some-realizations-on-foss-governance/</link>
      <pubDate>Wed, 07 Oct 2015 18:10:06 +0000</pubDate>
      
      <guid>/some-realizations-on-foss-governance/</guid>
      <description>If you haven’t read/paid attention to the Numpy Governance Discussions goingon in the numpy discussion mailing list, I wouldn’t blame you. They’re probably dry and boring.
But, for me, as someone who has been involved in a few Free/Open source communities over the past 8 years, I’m sensing a very interesting divide in the Numpy discussion (and FOSS Python more broadly) that I think is presented more strongly there than I’ve seen it elsewhere.</description>
    </item>
    
    <item>
      <title>Two points in learning to program</title>
      <link>/two-points-in-learning-to-program/</link>
      <pubDate>Tue, 06 Oct 2015 01:17:56 +0000</pubDate>
      
      <guid>/two-points-in-learning-to-program/</guid>
      <description>I feel like there are two big, “pivotal” realizations in my story so far of learning to program. While I’m sure not everyone moves from Haskell to Shen to R to Python before really feeling competent in a language, I have seen many peers grapple with them. 
1. Separate your code and data. I think this would be more aptly stated as Think Abstractly, but that belies the immediacy that the first statement provides.</description>
    </item>
    
    <item>
      <title>On the subject of porting,</title>
      <link>/on-the-subject-of-porting/</link>
      <pubDate>Thu, 30 Jul 2015 20:17:38 +0000</pubDate>
      
      <guid>/on-the-subject-of-porting/</guid>
      <description>On this, the first few minutes of Guido&amp;rsquo;s PyCon Keynote really hit home.
 Yes you should all be using Python 3, and I know that you all want to, but I know it&amp;rsquo;s difficult. You all have large amounts of Python 2 code in production that you&amp;rsquo;ve ported to Python 2.7.9 &amp;hellip; but the step to Python 3 from there is still phenomenal.
You can&amp;rsquo;t just fix a few style nets and remove a few L&amp;rsquo;s from long integers.</description>
    </item>
    
    <item>
      <title>and the dissertation begins in earnest</title>
      <link>/getting-excited-about-some-cool-new-exploration/</link>
      <pubDate>Wed, 29 Jul 2015 02:49:09 +0000</pubDate>
      
      <guid>/getting-excited-about-some-cool-new-exploration/</guid>
      <description>imported from: yetanothergeographer</description>
    </item>
    
    <item>
      <title>Reflections on a hard-won win for PySAL</title>
      <link>/reflections-on-a-hard-won-win-for-pysal/</link>
      <pubDate>Mon, 27 Jul 2015 21:10:56 +0000</pubDate>
      
      <guid>/reflections-on-a-hard-won-win-for-pysal/</guid>
      <description>As a way to learn Python (and I mean really come to know it), I took on the project of converting PySAL to be compatible with Python 3.
I started work on this two years ago. A tentative candidate for release is available in my fork
Now, I’m glad I did this. I still worry about the day when Apple decides to ship the next OSX (Half Moon Bay? Big Sur?</description>
    </item>
    
    <item>
      <title>compressing the entire census</title>
      <link>/that-compression-is-bewilderingly-good-the-full/</link>
      <pubDate>Mon, 27 Jul 2015 18:54:01 +0000</pubDate>
      
      <guid>/that-compression-is-bewilderingly-good-the-full/</guid>
      <description>Simply amazing.
 imported from: yetanothergeographer</description>
    </item>
    
    <item>
      <title>Gearing up for the last day of SciPy 2015</title>
      <link>/gearing-up-for-the-last-day-of-scipy-2015/</link>
      <pubDate>Sun, 12 Jul 2015 00:22:13 +0000</pubDate>
      
      <guid>/gearing-up-for-the-last-day-of-scipy-2015/</guid>
      <description>It&amp;rsquo;ll be a good one
 imported from: yetanothergeographer</description>
    </item>
    
    <item>
      <title>Untitled</title>
      <link>/i-usually-dont-think-much-about/</link>
      <pubDate>Thu, 18 Jun 2015 23:49:13 +0000</pubDate>
      
      <guid>/i-usually-dont-think-much-about/</guid>
      <description>I usually don’t think much about credentialization online. I have a few internet aliases (like yetanothergeographer) that I consider almost totally synonymous with my real name and persona. And even other personas on tumblr or other social networking sites are easily traced back to my “full” identity.
But, something that I found pretty shocking recently was the fact that any github profile you can find shows your public ssh keys to everyone.</description>
    </item>
    
    <item>
      <title>Cenpy Big Query</title>
      <link>/cenpy-big-query/</link>
      <pubDate>Tue, 16 Jun 2015 15:27:27 +0000</pubDate>
      
      <guid>/cenpy-big-query/</guid>
      <description>If you’ve been using my tools for census data exploration, as intensely as I&amp;rsquo;d hope you have, you might’ve noticed that the Census limits queries to 50 columns per query.
I’ve got your back, though. The newest release, cenpy 0.7, now supports n-column queries by chunking through 50-coulumns at a time. Be careful, though, as I&amp;rsquo;m sure if you pull down the entire Census 2010 short form in one go, you will probably get rate limited.</description>
    </item>
    
    <item>
      <title>business in the front, party distributed across 32 backs</title>
      <link>/mulitprocessing-business-in-the-front-parallel/</link>
      <pubDate>Fri, 12 Jun 2015 17:30:00 +0000</pubDate>
      
      <guid>/mulitprocessing-business-in-the-front-parallel/</guid>
      <description>imported from: yetanothergeographer</description>
    </item>
    
    <item>
      <title>Cenpy is now pip installable!</title>
      <link>/cenpy-is-now-pip-installable/</link>
      <pubDate>Thu, 11 Jun 2015 15:58:41 +0000</pubDate>
      
      <guid>/cenpy-is-now-pip-installable/</guid>
      <description>pip install cenpy
Check it out on github or its demo notebook on nbviewer.
yetanothergeographer:
 CenPy - An exploratory interface to the Census API So, I was looking to do some programmatic access to US Census Bureau data and was finding myself a little frustrated with how limited current tools in Python were to work with the connections. Mainly, most supported only a few protocols, provided no documentation or exploration functionality, and left it primarily up to exeternal documentation to provide information on how to query the API.</description>
    </item>
    
    <item>
      <title>“Maybe the Shapefile was right after all” is right after all</title>
      <link>/maybe-the-shapefile-was-right-after-all-is-right/</link>
      <pubDate>Sat, 06 Jun 2015 17:26:38 +0000</pubDate>
      
      <guid>/maybe-the-shapefile-was-right-after-all-is-right/</guid>
      <description>The more that I work with broad datasets, collected from many different means and used in many different contexts, the more I think that you really only need the &amp;ldquo;multi&amp;rdquo; instantiation of polygons, lines, and points. Usually, due to database typecasting, you want to coerce any heterogeneous datatypes into the same datatype. Since it&amp;rsquo;s much simpler to cast Polygons upwards into MultiPolygons, I&amp;rsquo;m rarely seeing any Polygons or Lines, even in datasets where the majority of features are single-component.</description>
    </item>
    
    <item>
      <title>Untitled</title>
      <link>/cenpy-an-exploratory-interface-to-the-census/</link>
      <pubDate>Fri, 05 Jun 2015 18:01:54 +0000</pubDate>
      
      <guid>/cenpy-an-exploratory-interface-to-the-census/</guid>
      <description>CenPy - An exploratory interface to the Census API So, I was looking to do some programmatic access to US Census Bureau data and was finding myself a little frustrated with how limited current tools in Python were to work with the connections. Mainly, most supported only a few protocols, provided no documentation or exploration functionality, and left it primarily up to exeternal documentation to provide information on how to query the API.</description>
    </item>
    
    <item>
      <title>Pip bug</title>
      <link>/heads-up-pip-bug/</link>
      <pubDate>Sat, 23 May 2015 14:33:14 +0000</pubDate>
      
      <guid>/heads-up-pip-bug/</guid>
      <description>Anyone running Debian testing/unstable, heads up on a breakage in pip that bit me this morning. Now I’m stuck with versions of ipython that dont work, as the apt package is broken and pip is broken.
Since I&amp;rsquo;m loath to install it manually, rather than through a package manager, I&amp;rsquo;m out of luck at the moment until the maintainer fixes the package. :(
 imported from: yetanothergeographer</description>
    </item>
    
    <item>
      <title>Happy GeoHacking</title>
      <link>/happy-geohacking/</link>
      <pubDate>Tue, 19 May 2015 03:06:16 +0000</pubDate>
      
      <guid>/happy-geohacking/</guid>
      <description>I just got done teaching a short workshop on GIS in Python. Something may be odd to those of you who use FOSS packages to do GIS: I didn&amp;rsquo;t use any GeoPandas.
This wasn&amp;rsquo;t a constraint I wanted. But, just getting pure pip-installable packages like Shapely and PySAL was difficult enough. The admins didn&amp;rsquo;t want to install one of the big scientific Python distributions and would only let something with minimal impact get used.</description>
    </item>
    
    <item>
      <title>there really is a big difference vis. scipy/numpy random sampling</title>
      <link>/this-is-insane-the-speed-differences-between/</link>
      <pubDate>Tue, 27 Jan 2015 22:01:33 +0000</pubDate>
      
      <guid>/this-is-insane-the-speed-differences-between/</guid>
      <description>The speed differences between Scipy and Numpy&amp;rsquo;s probability distributions is immense. Across the board, we see that numpy is almost twice as fast, in all cases. In the worst case, it&amp;rsquo;s hundreds of times faster. I wish scipy would put a warning or something on usage, cause waiting for some of these simulations I actually need to finish will be ridiculous. Thanks, scipy.  imported from: yetanothergeographer</description>
    </item>
    
    <item>
      <title>whyyyyy do we not use package managers everywhere?</title>
      <link>/my-time-using-linux-has-apparently-made-me-quite/</link>
      <pubDate>Tue, 17 Jun 2014 21:26:16 +0000</pubDate>
      
      <guid>/my-time-using-linux-has-apparently-made-me-quite/</guid>
      <description>I was doing some work in pandas and the append() function wouldn&amp;rsquo;t work as documented. Essentially, everything was conformable, but append() wouldn&amp;rsquo;t merge. Turns out I&amp;rsquo;m at least four versions behind on pandas, not to mention 3 versions of numpy and matplotlib.
Having one program that updates all your software is so desirable at this point that I can&amp;rsquo;t understand why the independent application install model still exists. Even Microsoft has its standardized .</description>
    </item>
    
    <item>
      <title>Going to Scipy 2014</title>
      <link>/going-to-scipy-2014/</link>
      <pubDate>Thu, 29 May 2014 10:02:09 +0000</pubDate>
      
      <guid>/going-to-scipy-2014/</guid>
      <description>anyone in Austin in July?
 imported from: yetanothergeographer</description>
    </item>
    
  </channel>
</rss>